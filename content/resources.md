+++
title= "Coding and open data resources for participants"
+++

# Computing and supplies

We recommend that every member of the team bring a laptop, if possible. You might find it helpful to have a mix of PCs and Macs, since they have different strengths.

We recommend that you make sure beforehand that the software you will be using throughout the weekend is properly installed and running on your computer. You will be working with a large dataset so make sure that you have the space for it on your hard drive.

You might want to bring some favorite statistical or computational reference books, if you have them, or bookmark some pages that you routinely refer to.

We will provide meals, snacks, and munchies. Feel free to bring anything additional you might want.


# Software

DataFest is software agnostic. If you can analyze and visualize data with it, it's welcome. We have compiled some brief resources that may be of help. R and Python tend to be the base programs people start with. And yes, a student in 2018 won one of the prizes after only having 5 week math 130 because he had enough working knowledge to help his team. 


## Code repository, version control, and collaboration

Reminder all git repositories used for DataFest MUST be private. 
    
* GitHub: https://www.github.com
* Happy Git with R: https://happygitwithr.com/


## R 

* New to R? Check out Chico's short course [Intro to R](https://norcalbiostat.github.io/MATH130/). All material is available freely from this site. 
* R cheat sheets: https://www.rstudio.com/resources/cheatsheets/
* RStudio is hosted on the cloud at https://rstudio.cloud/
* Data carpentry (great for new users, even if you're not a social scientist) https://preview.carpentries.org/r-socialsci/ 


## Python

* You can use a Python instance from Google Colab https://colab.research.google.com/ or on binder https://mybinder.org/ 
* Data carpentry (again, even for non ecologists) https://datacarpentry.org/python-ecology-lesson/ 

## Tableau

Good point and click, built in "black box" analysis (i think), often used in industry

- https://datascience.csuchico.edu/blog/2018/04/04/2018-04-10-intro_tableau_public_announce/ 

## SQL

Essential for joining tables

- https://datascience.csuchico.edu/blog/2022/09/01/2022-09-01-student-post-intro-sql/
- https://sqlbolt.com/ (interactive tutorial)
- https://datascience.csuchico.edu/blog/2019/02/13/2019-02-13-intro-sql/

## Text Wrangling

* https://www.tidytextmining.com/
* RegEx helper https://regex101.com/ 


# Presentations 

* [Data Visualization talk](https://media.csuchico.edu/media/InfoVis%3A%20Communicating%20Data%20Visually/0_je81u2r2)
* Making a good "elevator pitch"


# Data

At the end of the kickoff presentation each team should send one member to the registration desk and check out a USB stick containing the data. When you're done downloading the data off it please return it to the registration desk so that another team can use it.

## Large data advice

The dataset you will be working with is quite large. If you type a variable name to view it, it will take a while to display. Therefore, remember these R commands: `head()`, `tail()`, `str()`.

We strongly recommend you create a small data set that you can use to test things on. Then, if it works out, you can apply your procedure to the large dataset. Some procedures can take a frustratingly long time to run on large data sets, and so it will be comforting to know that your procedure works (because you tested it on a smaller data set) while you wait. We recommend taking a random sample of rows from the original data set, but there might be other approaches you find useful.

# Other 
Because why reinvent the wheel:

* Duke university: https://dukestatsci.github.io/datafest/resources.html
* Penn State: https://datafest.psu.edu/resources/

